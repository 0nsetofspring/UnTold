# 📑  **untold**

나도 몰랐던 나를 아는 방법

---

## 1. 프로젝트 한눈 보기

| 항목 | 요약 |
| --- | --- |
| **무엇** | 하나의 웹 탭에서 **아침 대시보드**(정보·감정 추천)와 **밤 자동 일기**(OCR·AI 초안)를 제공하는 올‑인‑원 서비스 |
| **누구** | 매일 정보를 모으고 기록하지만 “쓰는 시간” 때문에 포기했던 20‑40대 지식 노동자, 크리에이터 |

---

## 2. 핵심 기능 & 페이지

| 페이지 | 주요 요소 | 특징 |
| --- | --- | --- |
| **On‑Boarding** | PIN 만들기 → 위젯 선택 → 테마 | Framer Motion 슬라이드 |
| **Dashboard** | 카드(날씨·뉴스·환율·NASA·명언) + **MoodCard** | Drag 정렬·📌 스크랩 · 감정별 활동/음악 추천 |
| **Diary (월·일 뷰)** |  Markdown Editor · **AI 초안** 버튼 | ReinforceWriter 초안 → 수정 이벤트 학습 |
| **Widget Market** | ON/OFF · 순서 · API Key 입력 | 새 위젯 배포 가능 |
1. **USER FLOW**
    
    **TAB 1: Splash Screen & Login/Signup**
    
    - 회원가입과 함께 유저 선호 위젯 선택
        - 위젯은 추후 대쉬보드 구축 및, 일기 생성에 사용
    
    **TAB 2: DashBoard**
    
    - 유저 선호 위젯 배치
        - 선택지1: 유저가 드래그 방식으로 대쉬보드 레이아웃 자유롭게 형성 가능
        - 선택지2: 내부적으로 자동 레이아웃
    - 오늘의 감정을 예측하고 상응하는 멘트 출력
    - 구현 기획서
        
        
        | 모델 이름 | 입력 데이터 | 모델 방식 | 출력 | 목적 |
        | --- | --- | --- | --- | --- |
        | ① KoBERT 감정분류기 | 텍스트(일기 / URL 제목) | Fine-tuned Transformer | 감정 분포 (예: joy: 0.7, sad: 0.2...) | 일기에서 감정 패턴 추출 → 시계열 입력값 생성용 |
        | ③ 감정 시계열 예측기 | 최근 N일간 감정 벡터 시퀀스 | 시계열 예측 모델 (LSTM) | 오늘의 감정 예측 벡터 | 감정 흐름을 고려한 더 정교한 예측 감정 도출 |
        | ④ 멘트 생성기 | - 오늘 예측된 감정 벡터 (예: `sad` 0.6)
        - 사용자 설정 위젯 (예: "책", "음악", "산책") | Gemini | 예측된 감정에 따라 **멘트 유형 결정**사용자 위젯 중 하나를 활용한 멘트 템플릿 적용 | - 유연한 문장 생성
        - 감정 nuance에 따라 다채롭게 반응
        - 고도 개인화 가능 |
        - KoBERT
            - 작동 방식
                1. **자연어 입력 :** `"오늘 하루 너무 힘들었어..."`
                2. **토크나이징 (Tokenizing)**
                    - **문장을 잘게 쪼개고**, 각 토큰에 **숫자 ID**를 부여
                    - 예:
                        
                        `"오늘 하루 너무 힘들었어"`
                        
                        → `[CLS] 오늘, 하루, 너무, 힘들, 었, 어, [SEP]`
                        
                        → `[2, 1534, 827, 3983, 592, 111, 3]` 
                        
                3. **임베딩 + CLS 토큰 생성**
                    - **수백 차원의 벡터**로 변환돼요.
                    - 입력 맨 앞에 [CLS]라는 토큰을 붙여 이 **[CLS] 벡터 하나만** 뽑아서 **문장 전체 의미**를 요약
                        
                        👉 이게 바로 감정 분류에 쓰이는 대표 벡터
                        
                4. **Classification Head로 전달**
                    - [CLS] 벡터는 모델 마지막의 **분류기 (Classification Head)**로 들어감.
                    - 이감정별 확률을 뽑고, 최종 감정은 **가장 높은 확률값**을 가진 것
            - fine-tuning:
                - 선택지1: 사용자별 fine-tuning
                - 선택지2: 이미 fine-tuning된 huggingface의 모델 사용
        - LSTM
            - 목적 : 감정과 같은 **시계열 데이터**에서 장기적인 의존성을 기억하고 예측
            - 작동 방식 :
            - 기본 구성 요소
                - 기억 셀
                    
                    
                    | 구성 요소 | 설명 |
                    | --- | --- |
                    | **Cell state (`Cₜ`)** | 정보를 장기적으로 기억하는 메인 통로 |
                - 기억 셀을 조절하는 3가지 게이트
                    
                    
                    | 구성 요소 | 설명 |
                    | --- | --- |
                    | **Forget gate** | 현재 시점에서 어떤 정보를 지워야 할지 결정 |
                    | **Input gate** | 어떤 정보를 새롭게 저장할지 결정 |
                    | **Output gate** | 현재 시점에서 어떤 값을 출력으로 보낼지 결정 |
            - fine-tuning
                - 튜닝 요소
                    1. 입력 구조 관련
                        1. 시퀀스 길이 : 5일
                        2. 입력 벡터 구조 :  soft vector
                    2. 모델 구조 관련
                        
                        
                        | 항목 | 설명 | 값 |
                        | --- | --- | --- |
                        | Layer 수 | 더 복잡한 감정 흐름 학습 가능 | `2` |
                        | Hidden size | 각 LSTM 층 안에 있는 노드 개수 ( 많을수록 더 풍부하고 세밀한 표현 가능) | `128` |
                        | Dropout | 학습 중에 일부 뉴런을 **임시로 끄는** 확률
                        → **일부 정보를 의도적으로 제거**해서 **일반화 능력을 향상** | `0.3` |
                    3. 학습 관련
                        1. Loss function : 예측값과 실제 감정 차이를 측정
                            - MSE Loss :  각 감정별 차이 제곱해서 평균
                            
                            | 항목 | 설명 |
                            | --- | --- |
                            | **예측값** (`ŷ`) | 오늘의 감정 흐름을 바탕으로 LSTM이 예측한 내일 감정 분포 |
                            | **실제값** (`y`) | 유저가 다음날 일기에서 표현한 감정 (직접 선택 or 자동 추출) |
            - 과적합
                - 모델이 훈련 데이터에는 너무 잘 맞지만 새로운 데이터(= 실제 환경)에서는 성능이 뚝 떨어지는 현상
                
                ## 🧯 과적합을 막는 방법
                
                | 방법 | 설명 |
                | --- | --- |
                | ✅ Dropout | 학습 중 일부 뉴런 끄기 (랜덤으로!) |
                | ✅ Early Stopping | 검증 성능이 안 좋아지면 학습 중단 |
                | ✅ 정규화 | 파라미터가 너무 커지지 않게 제한 |
                | ✅ 데이터 늘리기 | 더 다양한 감정 예시를 보여주기 |
                | ✅ 모델 단순화 | Layer 수나 hidden size를 줄이기 |
        - **최종 감정 계산 공식 (가중 평균)**
            - 직전 감정일수록 더 높은 가중치를 반영해 오늘의 감정 벡터를 계산
            
            ```json
            # 예시: 최근 3일 감정 벡터 → 오늘 감정 예측
            # 감정 벡터 = {"joy": x, "sad": y, ...}
            # 가중치 예: [0.5, 0.3, 0.2] (가장 가까운 날이 0.5)
            
            weights = [0.5, 0.3, 0.2]
            emotions = [emotion_day_1, emotion_day_2, emotion_day_3]
            
            today_emotion = sum(w * e for w, e in zip(weights, emotions))
            ```
            
            - **거리 기반 가중치 함수 예시**:
                
                `w(t) = e^{-λt}` 형태로 점점 감소 (λ는 decay rate)
                
            - 💡 더 긴 시계열(7~14일)을 쓸 수도 있고, smoothing 기법도 적용 가능
        
    
    **TAB 3: Diary Generate**
    
    - UserFlow
        - 진입 로직) 메인 사이드바 ▶︎ Diary 아이콘 클릭
        - Diary Home
            - FullCalendar 뷰 → 요일/공휴일 플래그? 캘린더 api?
            - 오늘 날짜 하이라이트 (Primary 색)
            - 작성된 날짜에는 특정 표시 (ex. 기분 표시 or 일기제목+간단요약 or ● Badged dot) … 예뿌겡
            - date click 세부 플로우
                - **Diary Doc** : `diaries` 테이블의 1 row (`id`, `date`, `body_md`, `mood`, `tags[]`)
                - **Scrap** : 위젯📌·블록 (`scraps` 테이블)
                - Chrome 로그에서 저장된 JSON 블록
                - **Draft Zone** : “에디터에 아직 투입되지 않은 임시 카드” 영역
                
                ```json
                ┌─Header────────────────────────────────┐
                │ 8월 4일 (금)     Mood😊 Slider     [Save]│
                └─────────────────────────────────────────┘
                ┌────── Draft Zone  (drop area) ──────┐
                │ [ Card ] 뉴스스크랩    drag→  │
                │ [ Card ] ChromeURL            │
                │ [ + ] 업로드 (이미지·음성)     │
                └────────────────────────────────────┘
                ┌─Markdown Editor───────────────┐  
                │ # 제목 (자동 제안)                │ 
                │                               │  
                └───────────────────────────────┘ 
                            [ Generate ✨ ]  [ Cancel ]
                ```
                
                - Generate 후에도 사용자는 추가 수정 → Save 필수
    - 강화학습
        - 작동 방식 정리
            - 🧠 기본 구조
                - **한 번의 일기 생성 과정** = **하나의 Episode**
                - 에이전트는 이 Episode에서
                    
                    `글감 선택 → 순서 정하기 → Generate → 사용자 반응 확인`
                    
                    이 일련의 행동들을 수행
                    
                
                그때마다 사용자 반응(수정했는지, 저장했는지 등)에 따라
                
                👉 각각의 **보상(reward)** 이 발생하고,
                
                👉 에이전트는 **이 모든 행동 시퀀스의 누적 보상 (total reward)** 을 계산해
                
            - 📅 보상이 날마다 달라질 수도 있다?
                - 어떤 날은 **감정과 잘 맞는 일기**를 생성해도 사용자가 피곤해서 수정할 수 O
                - 어떤 날은 **감정 예측 자체가 실패**해서 좋은 일기를 생성하기 어려울 수 O
                
                즉, 강화학습 입장에서 보면 **보상은 stochastic(확률적)** 성격을 띠게 됨
                
                > 같은 행동을 해도 날마다 다른 결과 (= 다른 보상)을 받을 수 있다는 뜻!
                > 
            - 🔄 에이전트가 배우는 것
                
                > “어떤 상태(ex. 감정 상태 + 글감 조합 + 문체 스타일)에서
                > 
                > 
                > **어떤 행동을 했을 때 평균적으로 높은 보상**을 받더라!”
                > 
                > 를 **통계적으로 학습**
                > 
                
                👉 **수백, 수천 번의 일기 작성 데이터를 기반으로**,
                
                👉 어떤 행동이 **장기적으로 높은 보상을 주는지**를 학습
                
                💡 목표 : 에이전트의 행동 정책이 최대한의 누적 보상을 얻게 만드는 것
                
            
        - 에이전트 정의
            - 사용 데이터
                - 오늘 글감
                    - 스크랩한 위젯 기록들
                    - 크롬 로그
                    - 당일 감정 라벨
                    - 유저가 업로드한 이미지/텍스트 등
                - 지난 데이터
                    - **과거 내 일기 스타일** (문체, 자주 쓰는 템플릿)
                    - 편집 차이 값?
            - 결정 데이터
                - 어떤 카드(스크랩/URL/이미지 등)를 넣을지
                - 어떤 순서로 배치할지
                - 제목이나 문체 스타일을 어떻게 조절할지
            - 보상
                - 1️⃣ 💬 기본 철학: "유저 만족을 최우선으로"
                    - Diary Agent의 **학습 목표**는 → "유저가 만족할 만한 일기를 생성하는 것"
                    - 이 만족은 단지 **정확성**이 아니라,
                        
                        👉 유저의 **감정**, **문체 스타일**, **글감 배치**, 그리고 **수정 여부**에 반응해야 함!
                        
                - 2️⃣ 🎯 보상 시스템 전반 구조
                    - 1개의 일기 생성 = 1개의 Episode
                    - Episode 안에서 여러 평가 지표(Rᵢ)를 산출 → 가중합하여 총 보상 R 계산
                    - 학습은 이 **R_total**을 기준으로 policy를 업데이트함
                    
                    ```
                    R_total = w1·R_문체 + w2·R_레이아웃 + w4·R_유저반응
                    ```
                    
                    → 에이전트는 **이 총 보상**을 최대화하려고 학습함
                    
                    → 그러나 **각 영역별 점수도 함께 기록**해서 개선·개인화·분석에 사용
                    
                - 3️⃣ 🧩 보상 항목별 세부 정의
                    
                    ### ✅ A. 문체 만족도 (R_문체)
                    
                    **목표:** 에이전트가 유저의 스타일을 얼마나 잘 재현했는가?
                    
                    | 기준 | 보상 점수 | 설명 |
                    | --- | --- | --- |
                    | 수정 없이 저장 (diff ≥ 0.9) | `+0.4` | 유저가 문체를 매우 만족 |
                    | 일부 수정 (0.6 ~ 0.9) | `+0.2` | 어느 정도 문체 일치 |
                    | 대폭 수정 (diff < 0.6) | `-0.4` | 문체 불만족 |
                    | 유저가 직접 문체 삭제/재작성 | `-1.0` | 완전 실패 |
                    
                    💡 *선택적으로*: 문체 임베딩 유사도(Cosine Similarity)도 함께 고려할 수 있음
                    
                    → `최종 문체 만족도 = 0.3·(문체 유사도) + 0.7·(행동 기반 만족도)`
                    
                    ---
                    
                    ### ✅ B. 레이아웃 만족도 (R_레이아웃)
                    
                    **목표:** 추천한 글감 배치가 적절했는가?
                    
                    | 기준 | 보상 점수 | 설명 |
                    | --- | --- | --- |
                    | 카드 그대로 사용 | `+0.2` (개당) | 추천 순서가 좋았음 |
                    | 순서만 바꿈 | `+0.1` | 추천은 맞았지만, 사용자가 배열 |
                    | 일부 카드 제거 | `-0.1` (개당) | 일부 카드가 부적절 |
                    | 전부 제거 후 새로 구성 | `-0.3` | 추천 완전 실패 |
                    
                    ---
                    
                    ### ✅ D. 사용자 반응 (R_유저반응)
                    
                    **목표:** 생성된 일기가 전반적으로 만족스러웠는가?
                    
                    | 행동 | 보상 |
                    | --- | --- |
                    | Generate 후 즉시 저장 | `+1.0` |
                    | 수정 후 저장 | `+0.6` |
                    | 저장 안 함 (Cancel 등) | `-0.4` |
                    | 삭제 후 직접 작성 | `-1.0` |
                    | 👍 "좋았어요" 클릭 | `+1.0` |
                    | 👎 "별로예요" 클릭 | `-1.0` |
                - 4️⃣ 🧠 보상은 어떻게 작동하나?
                    - 보상은 **각 행동마다 생성**되고
                    - 하나의 일기 작성 Episode가 끝나면 **총 보상(R_total)** 으로 정리됨
                    - 이 보상이 **강화학습 모델(PPO, DQN 등)의 학습 목표**가 됨
                    
                    ```python
                    total_reward = w1 * style_score + w2 * layout_score + ...
                    ```
                    
                    - 학습은 `R_total`을 기준으로 이루어지지만
                    - `각 영역별 Rᵢ`는 저장해서 **디버깅, 분석, 개인화**에 사용!
                
                ```json
                {
                  "date": "2025-07-27",
                  "reward_breakdown": {
                    "style": 0.4,
                    "layout": 0.2,
                    "emotion": 0.3,
                    "feedback": 0.6
                  },
                  "total_reward": 1.5
                }
                
                ```
                
            - 목표
                - 적절한 글감 조합과 문체로 사용자 맞춤형 일기 생성
                - 사용자 수정 최소화, 만족도 최대화
                - 감정 흐름과 일기 내용의 일관성 유지
                - 문체와 일기 스타일을 사용자 맞춤형으로 진화시킴
        - flow
            - 입력해석
            - 상태구성
            - 행동결정
            - 텍스트 생성
            - 사용자 반응 → 보상 계산
            - 강화학습 업데이트





# 🚀 프로젝트 기술 스택 요약
## 🧩 1. Frontend
| 항목     | 기술                                   | 설명                         |
| ------ | ------------------------------------ | -------------------------- |
| 프레임워크  | **React.js / Next.js**               | SPA 기반, 서버사이드 렌더링(SSR)도 가능 |
| 상태관리   | **Context API** (or Recoil, Zustand) | 위젯 정보, 감정 상태 등 전역 공유       |
| 스타일링   | **Tailwind CSS**                     | 유틸리티 기반 CSS 프레임워크          |
| 라우팅    | **Next.js Pages Router**             | `pages/` 기반의 파일 라우팅        |
| 타입 시스템 | **TypeScript**                       | 정적 타입을 통한 안정성 확보           |
| API 호출 | **axios / fetch**                    | 백엔드 API와의 데이터 통신           |


## 🧠 2. Backend
| 항목          | 기술                   | 설명                                 |
| ----------- | -------------------- | ---------------------------------- |
| 서버 프레임워크    | **FastAPI (Python)** | 빠르고 모던한 Python 기반 웹 프레임워크          |          |
| 마이그레이션      | **Alembic**          | DB 구조 변경 관리                        |
| 환경변수 관리     | **python-dotenv**    | `.env.local`, `.env.remote` 관리     |
| REST API 설계 | FastAPI 라우터 기반       | `/api/diary`, `/api/widget` 등으로 설계 |
| Seed Script | `seed_data.py`       | 초기 테스트용 더미 데이터 삽입                  |


## 🧠 3. AI / ML 관련
| 항목        | 기술                              | 설명                                                       |
| --------- | ------------------------------- | -------------------------------------------------------- |
| 감정 분석     | **KoBERT (from SKT)**           | 한국어 문장 기반 감정 분류기 (fine-tuning or HuggingFace pretrained) |
| 감정 시계열 예측 | **LSTM (PyTorch)**              | 지난 감정 흐름 → 오늘 감정 예측                                      |
| 멘트 생성     | **Gemini API** | 감정 기반 멘트 생성 (위젯 기반 추천 포함)                                |


## ☁️ 4. 데이터베이스 & 배포
| 항목        | 기술                           | 설명                         |
| --------- | ---------------------------- | -------------------------- |
| 로컬 DB     | **SQLite**                   | 빠르고 가벼운 파일형 DB             |
| 협업/배포용 DB | **Supabase (PostgreSQL)**    | 클라우드 기반 실시간 공유 DB          |
| .env 관리   | `.env.local` / `.env.remote` | SQLite vs PostgreSQL 전환 가능 |
| DB 클라이언트  | Supabase Web Console         | 웹 UI로 테이블/데이터 관리 가능        |


## 🤝 5. 버전 관리 / 협업 툴
| 항목       | 기술                                     | 설명                     |
| -------- | -------------------------------------- | ---------------------- |
| 버전 관리    | **Git + GitHub**                       | 소스 버전 관리 & 이슈 관리       |
| 협업 문서    | **Notion**               | 기획서, 테스크, API 명세 공유용   |



# 📁 디렉터리 구조 with 주석
UnTold/
├── backend/                         # ✅ 백엔드 (FastAPI + ML + 강화학습)
│   ├── main.py                      # FastAPI 앱 진입점
│
│   ├── db/                          # ✅ DB 관련 모듈 통합
│   │   ├── models/                  # DB 모델 정의
│   │   │   ├── user.py              # 유저 테이블
│   │   │   └── diary.py             # 일기 테이블
│   │   ├── connect.py               # DB 연결 로직
│   │   ├── seed/                    # 초기 데이터 삽입
│   │   │   └── seed_data.py
│   │   └── alembic/                 # 마이그레이션 도구
│   │       ├── versions/            # 마이그레이션 이력
│   │       └── env.py
│
│   ├── api/                         # ✅ FastAPI 라우터 모음
│   │   ├── user_router.py           # 유저 관련 API
│   │   └── diary_router.py          # 일기 작성 & 감정 저장 API
│
│   ├── ml/                          # ✅ 머신러닝 API/모듈
│   │   ├── emotion_predictor.py     # LSTM 기반 감정 예측
│   │   ├── style_vector.py          # KoBERT 기반 문체 벡터 추출
│   │   └── generate.py              # 감정 멘트 생성 API (GPT 등)
│
│   ├── rl/                       # ✅ 강화학습 학습용 모듈
│   │   ├── train_rl_agent.py        # PPO 학습 루프
│   │   ├── reward_scheme.py         # 보상 설계
│   │   └── utils.py                 # 텍스트 전처리 등 유틸
│
│   ├── .env.local                   # SQLite 연결용 설정
│   ├── .env.remote                  # Supabase PostgreSQL 설정
│   └── requirements.txt            # Python 의존성 목록
│
├── frontend/                        # ✅ 프론트엔드 (React + TS + Tailwind)
│   ├── public/                      # 정적 파일
│   ├── src/
│   │   ├── pages/                   # ✅ 페이지별 폴더
│   │   │   ├── dashboard/
│   │   │   │   ├── index.tsx        # 감정 대시보드 메인
│   │   │   │   ├── DashboardChart.tsx  # 차트 컴포넌트
│   │   │   │   └── useEmotionFetch.ts  # 대시보드 감정 데이터 훅
│   │   │   │
│   │   │   ├── write-diary/
│   │   │   │   ├── index.tsx
│   │   │   │   ├── DiaryEditor.tsx
│   │   │   │   └── useDiaryForm.ts
│   │   │   │
│   │   │   ├── widget-store/        # 🧩 위젯 스토어
│   │   │   │   ├── index.tsx
│   │   │   │   ├── WidgetCard.tsx       # 위젯 카드 UI
│   │   │   │   ├── useWidgetList.ts     # 위젯 불러오기 훅
│   │   │   │   └── widgetAPI.ts         # 위젯 관련 API
│   │   │   │
│   │   ├── components/              # ✅ 다수 페이지에서 재사용되는 UI
│   │   │   ├── EmotionBar.tsx
│   │   │   └── LoadingSpinner.tsx
│   │   ├── api/                     # ✅ 공통 API 요청 함수
│   │   │   └── axiosInstance.ts
│   │   ├── hooks/                   # ✅ 공통 커스텀 훅
│   │   │   ├── useUser.ts
│   │   │   └── useAuth.ts
│   │   ├── store/                   # ✅ 전역 상태 관리
│   │   │   └── useUserStore.ts
│   │   └── App.tsx                  # 앱 루트 엔트리
│
│   ├── .env                         # 프론트 환경변수
│   ├── tailwind.config.js
│   ├── postcss.config.js
│   └── package.json
│
├── ml/                              # ✅ 독립 모델 학습 모듈
│   ├── train_kobert.py              # KoBERT 감정 분류 학습
│   ├── train_lstm.py                # LSTM 감정 예측 학습
│   └── evaluate.py                  # 모델 평가용 스크립트
│
├── docs/                            # 📄 기획서 및 설명 문서
│   ├── proposal.md                  # 지금 이 파일
│   ├── reward_design.md
│   └── api_spec.md
│
├── scripts/                         # 💡 배포용 스크립트 또는 샘플
│   └── export_supabase.sh
│
└── README.md                        # 📘 프로젝트 설명서
